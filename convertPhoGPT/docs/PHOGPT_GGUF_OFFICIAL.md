# ‚úÖ Official PhoGPT GGUF - No Conversion Needed!

Great news! VinAI has released **official GGUF versions** of PhoGPT that work directly with Ollama.

## üì¶ Available Models

**Model**: [vinai/PhoGPT-4B-Chat-gguf](https://huggingface.co/vinai/PhoGPT-4B-Chat-gguf)

| Quantization | Size | Quality | Use Case |
|--------------|------|---------|----------|
| **Q4_K_M** | 2.36 GB | Good | ‚úÖ Recommended - Best balance |
| **Q8_0** | 3.92 GB | Excellent | High quality, more memory |

**Specifications**:
- üáªüá≥ Vietnamese-optimized
- üìä Trained on 102B Vietnamese tokens
- üí¨ Fine-tuned on 70K instructions + 290K conversations
- üìù 8192 token context length
- üéØ 20,480 vocabulary size

## üöÄ Quick Setup (5 Minutes)

### Option 1: Direct Pull from Hugging Face (Easiest)

```bash
# Pull Q4_K_M (recommended)
ollama pull hf.co/vinai/PhoGPT-4B-Chat-gguf:Q4_K_M

# Or Q8_0 (higher quality)
ollama pull hf.co/vinai/PhoGPT-4B-Chat-gguf:Q8_0
```

### Option 2: Download and Import

#### Step 1: Download GGUF File

```bash
# Method A: Using huggingface-cli
huggingface-cli download vinai/PhoGPT-4B-Chat-gguf \
    phogpt-4b-chat-q4_k_m.gguf \
    --local-dir ./models

# Method B: Manual download
# Go to: https://huggingface.co/vinai/PhoGPT-4B-Chat-gguf/tree/main
# Download: phogpt-4b-chat-q4_k_m.gguf (2.36 GB)
```

#### Step 2: Create Modelfile

```bash
cd e:\QC_tech\SanViecLam\SanViecLam.Chatbot\job_bot

# Create Modelfile
cat > Modelfile.phogpt <<EOF
# Official PhoGPT 4B Chat GGUF
FROM ./models/phogpt-4b-chat-q4_k_m.gguf

# Optimized parameters for Vietnamese job search
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER top_k 50
PARAMETER num_ctx 4096
PARAMETER num_predict 2048
PARAMETER stop "### C√¢u h·ªèi:"
PARAMETER stop "<|endoftext|>"

# System prompt for job search
SYSTEM """B·∫°n l√† tr·ª£ l√Ω AI chuy√™n nghi·ªáp v·ªÅ t√¨m ki·∫øm vi·ªác l√†m v√† t∆∞ v·∫•n ngh·ªÅ nghi·ªáp t·∫°i Vi·ªát Nam.

Nhi·ªám v·ª• c·ªßa b·∫°n:
1. Hi·ªÉu v√† ph√¢n t√≠ch y√™u c·∫ßu t√¨m vi·ªác c·ªßa ng∆∞·ªùi d√πng
2. S·ª≠ d·ª•ng c√°c c√¥ng c·ª• (tools) ƒë·ªÉ t√¨m ki·∫øm vi·ªác l√†m ph√π h·ª£p
3. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát t·ª± nhi√™n, chuy√™n nghi·ªáp v√† th√¢n thi·ªán
4. Cung c·∫•p th√¥ng tin ch√≠nh x√°c, c·ª• th·ªÉ v·ªÅ c√¥ng vi·ªác

Khi ng∆∞·ªùi d√πng h·ªèi v·ªÅ vi·ªác l√†m:
- Lu√¥n s·ª≠ d·ª•ng c√¥ng c·ª• job_search ƒë·ªÉ t√¨m ki·∫øm
- Tr√≠ch xu·∫•t t·ª´ kh√≥a ch√≠nh x√°c (v·ªã tr√≠, ƒë·ªãa ƒëi·ªÉm, ng√†nh ngh·ªÅ)
- T·ªïng h·ª£p k·∫øt qu·∫£ m·ªôt c√°ch r√µ r√†ng, d·ªÖ hi·ªÉu"""

# PhoGPT prompt template
TEMPLATE """### C√¢u h·ªèi: {{ .Prompt }}
### Tr·∫£ l·ªùi:"""

MESSAGE system """{{ .System }}"""
MESSAGE user """### C√¢u h·ªèi: {{ .Content }}"""
MESSAGE assistant """### Tr·∫£ l·ªùi: {{ .Content }}"""
EOF
```

#### Step 3: Create Ollama Model

```bash
ollama create phogpt-4b-chat -f Modelfile.phogpt
```

#### Step 4: Test

```bash
ollama run phogpt-4b-chat "Xin ch√†o, t√¨m vi·ªác k·ªπ s∆∞ ph·∫ßn m·ªÅm t·∫°i H√† N·ªôi"
```

#### Step 5: Update Your Application

```bash
# Edit .env or agent_lightning/.env
LLM_MODEL=phogpt-4b-chat
QWEN_MODEL=phogpt-4b-chat

# Restart service
python job_bot/main.py
```

## üéØ Complete Setup Script

Save this as `setup_phogpt_official.bat` (Windows):

```batch
@echo off
echo ==========================================
echo PhoGPT Official GGUF Setup
echo ==========================================

echo.
echo Step 1: Downloading PhoGPT GGUF...
huggingface-cli download vinai/PhoGPT-4B-Chat-gguf phogpt-4b-chat-q4_k_m.gguf --local-dir ./models

echo.
echo Step 2: Creating Ollama model...
cd job_bot
ollama create phogpt-4b-chat -f Modelfile.phogpt

echo.
echo Step 3: Testing model...
ollama run phogpt-4b-chat "Xin ch√†o, b·∫°n l√† ai?"

echo.
echo ==========================================
echo Setup Complete!
echo ==========================================
echo.
echo Update your .env file:
echo   LLM_MODEL=phogpt-4b-chat
echo.
echo Then restart your service:
echo   python job_bot/main.py
echo.
pause
```

Or Linux/Mac (`setup_phogpt_official.sh`):

```bash
#!/bin/bash
echo "=========================================="
echo "PhoGPT Official GGUF Setup"
echo "=========================================="

echo ""
echo "Step 1: Downloading PhoGPT GGUF..."
huggingface-cli download vinai/PhoGPT-4B-Chat-gguf \
    phogpt-4b-chat-q4_k_m.gguf \
    --local-dir ./models

echo ""
echo "Step 2: Creating Ollama model..."
cd job_bot
ollama create phogpt-4b-chat -f Modelfile.phogpt

echo ""
echo "Step 3: Testing model..."
ollama run phogpt-4b-chat "Xin ch√†o, b·∫°n l√† ai?"

echo ""
echo "=========================================="
echo "‚úì Setup Complete!"
echo "=========================================="
echo ""
echo "Update your .env file:"
echo "  LLM_MODEL=phogpt-4b-chat"
echo ""
echo "Then restart your service:"
echo "  python job_bot/main.py"
```

## üìä Comparison

| Feature | Official PhoGPT GGUF | Converted PhoGPT | Qwen3 8B |
|---------|----------------------|------------------|----------|
| **Setup Difficulty** | ‚≠ê Very Easy | ‚ùå Failed | ‚≠ê Easy |
| **Download Size** | 2.36 GB | N/A | ~4.5 GB |
| **Vietnamese Quality** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | N/A | ‚≠ê‚≠ê‚≠ê |
| **Tool Calling** | ‚≠ê‚≠ê‚≠ê | N/A | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Speed (GPU)** | Fast | N/A | Fast |
| **Official Support** | ‚úÖ Yes | ‚ùå No | ‚úÖ Yes |

## üéÅ Why This is Better

**vs Manual Conversion**:
- ‚úÖ No conversion errors
- ‚úÖ Official VinAI release
- ‚úÖ Pre-optimized quantization
- ‚úÖ 5-minute setup vs hours of troubleshooting

**vs Other Vietnamese Models**:
- ‚úÖ Most Vietnamese-focused (102B tokens)
- ‚úÖ Largest instruction dataset (70K + 290K)
- ‚úÖ Official from VinAI Research
- ‚úÖ Active maintenance

## üîß Troubleshooting

### Download Fails

```bash
# Try alternative download
wget https://huggingface.co/vinai/PhoGPT-4B-Chat-gguf/resolve/main/phogpt-4b-chat-q4_k_m.gguf

# Or use browser
# Go to: https://huggingface.co/vinai/PhoGPT-4B-Chat-gguf/tree/main
# Click download
```

### Model Not Found in Ollama

```bash
# List models
ollama list

# If missing, recreate
ollama create phogpt-4b-chat -f Modelfile.phogpt
```

### Poor Tool Calling

PhoGPT may not be as good at tool calling as Qwen. Consider:
- Using more explicit system prompts
- Adding examples in the system message
- Hybrid approach (Qwen for tools, PhoGPT for responses)

## üìö Resources

- **Model Card**: https://huggingface.co/vinai/PhoGPT-4B-Chat-gguf
- **Original PhoGPT**: https://github.com/VinAIResearch/PhoGPT
- **Technical Paper**: [arXiv:2311.02945](https://arxiv.org/abs/2311.02945)
- **License**: BSD-3-Clause

## üìù Citation

If you use PhoGPT in your work:

```bibtex
@article{PhoGPT,
  title     = {{PhoGPT: Generative Pre-training for Vietnamese}},
  author    = {Dat Quoc Nguyen and Linh The Nguyen and Chi Tran and
               Dung Ngoc Nguyen and Dinh Phung and Hung Bui},
  journal   = {arXiv preprint},
  volume    = {arXiv:2311.02945},
  year      = {2023}
}
```

## ‚úÖ Next Steps

1. **Download**: Get `phogpt-4b-chat-q4_k_m.gguf` (2.36 GB)
2. **Create**: Make Ollama model with Modelfile
3. **Test**: Try `ollama run phogpt-4b-chat`
4. **Deploy**: Update `.env` and restart service
5. **Monitor**: Compare Vietnamese quality vs Qwen

## üéØ Recommendation

**Use this official GGUF version** instead of:
- ‚ùå Manual conversion (failed)
- ‚ùå Direct transformers integration (complex)
- ‚úÖ Simple, official, works out of the box

This is the **easiest and best solution** for Vietnamese support!
