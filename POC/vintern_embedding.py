!pip install flash_attn
!pip install decord
!pip install transformers==4.48.0
import torch
from PIL import Image
from transformers import AutoModel, AutoTokenizer, AutoProcessor
import matplotlib.pyplot as plt

model_name = "5CD-AI/Vintern-Embedding-1B"

processor =  AutoProcessor.from_pretrained(
    model_name,
    trust_remote_code=True
)
model = AutoModel.from_pretrained(
    model_name,
    torch_dtype=torch.bfloat16,
    low_cpu_mem_usage=True,
    trust_remote_code=True,
).eval().cuda()
!wget https://huggingface.co/5CD-AI/ColVintern-1B-v1/resolve/main/ex1.jpg
!wget https://huggingface.co/5CD-AI/ColVintern-1B-v1/resolve/main/ex2.jpg
images = [Image.open("ex1.jpg"), Image.open("ex2.jpg")]
batch_images = processor.process_images(images)

queries = [
    "C·∫£ng H·∫£i Ph√≤ng ·ªü ƒë√¢u ?",
    "Ph√≠ giao h√†ng bao nhi√™u ?",
]
batch_queries = processor.process_queries(queries)

text_documents = [
    "C·∫£ng H·∫£i Ph√≤ng l√† m·ªôt c·ª•m c·∫£ng bi·ªÉn t·ªïng h·ª£p c·∫•p qu·ªëc gia, l·ªõn th·ª© 2 ·ªü Vi·ªát Nam sau c·∫£ng S√†i G√≤n, l√† c·ª≠a ng√µ qu·ªëc t·∫ø c·ªßa Vi·ªát Nam, n·∫±m t·∫°i ba qu·∫≠n H·ªìng B√†ng, Ng√¥ Quy·ªÅn v√† H·∫£i An. B√™n c·∫°nh ƒë√≥, c√πng t√™n C·∫£ng H·∫£i Ph√≤ng (ti·∫øng Anh: Port of Hai Phong ho·∫∑c Hai Phong Port) l√† m·ªôt c·ª•m c·∫£ng bi·ªÉn thu·ªôc C√¥ng ty c·ªï ph·∫ßn c·∫£ng H·∫£i Ph√≤ng t·∫°i th√†nh ph·ªë H·∫£i Ph√≤ng, Vi·ªát Nam. ƒê√¢y l√† m·ªôt trong hai c·∫£ng bi·ªÉn t·ªïng h·ª£p l·ªõn v√† l√¢u ƒë·ªùi nh·∫•t t·∫°i Vi·ªát Nam, c√πng v·ªõi C√¥ng ty C·∫£ng S√†i G√≤n ·ªü ph√≠a Nam.",
    "S√¢n bay Chu Lai (t·ªânh Qu·∫£ng Nam) c≈©ng ƒë∆∞·ª£c h√£ng h√†ng kh√¥ng gi√° r·∫ª Vietjet ƒë·ªÅ xu·∫•t ƒë·∫ßu t∆∞ n√¢ng c·∫•p 20.000 t·ªâ ƒë·ªìng theo 3 giai ƒëo·∫°n t·ª´ 2020-2025 ƒë·ªÉ ƒë·∫øn nƒÉm 2025 tr·ªü th√†nh C·∫£ng h√†ng kh√¥ng qu·ªëc t·∫ø v√† tr·ªü th√†nh trung t√¢m trung chuy·ªÉn, v·∫≠n t·∫£i h√†ng h√≥a l·ªõn c·ªßa c·∫£ n∆∞·ªõc theo quy ho·∫°ch c·ªßa B·ªô GTVT nƒÉm 2015.",
]
batch_text_docs = processor.process_docs(text_documents)

raw_docs = images + text_documents

# ==============================
# 3. Move Tensors to GPU
# ==============================
batch_images["pixel_values"] = batch_images["pixel_values"].cuda().bfloat16()
batch_images["input_ids"] = batch_images["input_ids"].cuda()
batch_images["attention_mask"] = batch_images["attention_mask"].cuda().bfloat16()

batch_queries["input_ids"] = batch_queries["input_ids"].cuda()
batch_queries["attention_mask"] = batch_queries["attention_mask"].cuda().bfloat16()

batch_text_docs["input_ids"] = batch_text_docs["input_ids"].cuda()
batch_text_docs["attention_mask"] = batch_text_docs["attention_mask"].cuda().bfloat16()

# ==============================
# 4. Generate Embeddings
# ==============================
with torch.no_grad():
    image_embeddings = model(**batch_images)
    query_embeddings = model(**batch_queries)
    text_docs_embeddings = model(**batch_text_docs)

# ==============================
# 5. Compute Similarity Scores
# ==============================
scores = processor.score_multi_vector(
    query_embeddings,
    list(image_embeddings) + list(text_docs_embeddings)
)

max_scores, max_indices = torch.max(scores, dim=1)

# ==============================
# 6. Print Results
# ==============================
for i, query in enumerate(queries):
    print("=" * 100)
    print(f"Query: '{query}'")
    print(f"Score: {max_scores[i].item()}\n")

    doc = raw_docs[max_indices[i]]
    if isinstance(doc, str):
        print(f"Matched Text Document:\n{doc}\n")
    else:
        plt.figure(figsize=(5, 5))
        plt.imshow(doc)
        plt.axis("off")
        plt.show()
pip install --upgrade pymupdf
!wget https://datafiles.chinhphu.vn/cpp/files/vbpq/2019/12/100.signed_01.pdf
!wget https://datafiles.chinhphu.vn/cpp/files/vbpq/2019/12/100_2.pdf
!gdown 1w6jTTm6jTm0JzmQPwe_1POJ_AEZx__ri
!wget https://huggingface.co/datasets/khang119966/video/resolve/main/trieu_chung_benh.txt
import tqdm
import fitz
from datasets import load_dataset
page_list = []
for pdffile in ["100.signed_01.pdf","ƒê·ªãa l√≠ 9.pdf"]:
  doc = fitz.open(pdffile)
  for index in tqdm.tqdm(range(doc.page_count)):
      page = doc.load_page(index)
      pix = page.get_pixmap()
      img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
      page_list.append(img)
page_list = page_list[:200]
image_embeddings_list = []

for i in tqdm.tqdm(range(len(page_list))):
    batch_images = processor.process_images([page_list[i]])

    batch_images["pixel_values"] =  batch_images["pixel_values"].cuda().bfloat16()
    batch_images["input_ids"] = batch_images["input_ids"].cuda() #.bfloat16()
    batch_images["attention_mask"] = batch_images["attention_mask"].cuda().bfloat16()

    with torch.no_grad():
        image_embeddings = model(**batch_images)

    image_embeddings_list.append(image_embeddings.squeeze())
len(image_embeddings_list)
def split_text(text, chunk_size=1024, overlap=512):
    chunks = []
    start = 0
    if not isinstance(text, str):
        return []
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        chunks.append(chunk)
        start += chunk_size - overlap
    return chunks

with open("trieu_chung_benh.txt", 'r', encoding='utf-8') as f:
    content = f.read()
    text_chunk_list = split_text(content)

text_chunk_list = text_chunk_list[:200]
text_embeddings_list = []

for chunk in tqdm.tqdm(text_chunk_list):
  batch_text_docs = processor.process_docs([chunk])

  batch_text_docs["input_ids"] = batch_text_docs["input_ids"].cuda()
  batch_text_docs["attention_mask"] = batch_text_docs["attention_mask"].cuda().bfloat16()

  with torch.no_grad():
      text_docs_embeddings = model(**batch_text_docs)
      text_embeddings_list += list(text_docs_embeddings)
doc_embeddings_list = text_embeddings_list + image_embeddings_list
raw_docs = text_chunk_list + page_list
def search_and_print(query, processor, model, doc_embeddings_list, raw_docs, top_k=5, device="cuda"):
    """
    T√¨m ki·∫øm v√† in ra k·∫øt qu·∫£ top_k t√†i li·ªáu li√™n quan ƒë·∫øn query.
    - query: c√¢u truy v·∫•n (string)
    - processor: processor ƒë√£ load
    - model: model encode query
    - doc_embeddings_list: list embedding t√†i li·ªáu
    - raw_docs: list t√†i li·ªáu g·ªëc (text ho·∫∑c h√¨nh ·∫£nh)
    - top_k: s·ªë k·∫øt qu·∫£ mu·ªën hi·ªÉn th·ªã
    """
    # Chu·∫©n b·ªã batch query
    batch_queries = processor.process_queries([query])
    batch_queries["input_ids"] = batch_queries["input_ids"].to(device)
    batch_queries["attention_mask"] = batch_queries["attention_mask"].to(device).bfloat16()

    # T√≠nh embedding query
    with torch.no_grad():
        query_embeddings = model(**batch_queries)

    # T√≠nh ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng
    scores = processor.score_multi_vector(query_embeddings, doc_embeddings_list)[0]
    top_indices = scores.argsort(descending=True)[:top_k]

    print(f"\nüîç K·∫øt qu·∫£ t√¨m ki·∫øm cho query: \"{query}\"\n")
    for rank, idx in enumerate(top_indices, start=1):
        score = scores[idx].item()
        doc = raw_docs[idx]

        print(f"#{rank} | Score: {score:.4f}")
        print("=" * 60)
        if isinstance(doc, str):
            print(f"üìÑ VƒÉn b·∫£n: {doc}\n")
        else:
            print("üñºÔ∏è H√¨nh ·∫£nh:")
            plt.figure(figsize=(10, 10))
            plt.imshow(doc)
            plt.axis("off")
            plt.show()
search_and_print("ƒêi xe ng∆∞·ª£c chi·ªÅu b·ªã ph·∫°t bao nhi√™u ti·ªÅn ?", processor, model, doc_embeddings_list, raw_docs, top_k=5)